{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from models.conv3d_encdec.model import PlaceholderModel\n",
    "from models.conv3d_encdec.loader import SingleChannelDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = 'ns4486'\n",
    "model_num = 'NUM-13'\n",
    "\n",
    "run_through_model = True\n",
    "generate_input_images = True\n",
    "generate_output_images = True\n",
    "generate_videos = True\n",
    "\n",
    "inputs_outputs_save_path = f'/scratch/{userid}/capstone/results/{model_num}.npy'\n",
    "input_images_path = f'/scratch/{userid}/capstone/simulations/original_35th_frames'\n",
    "output_images_path = f'/scratch/{userid}/capstone/simulations/{model_num}/predict_35th_frames_model/'\n",
    "all_expected_predicted_video_path = f'/scratch/{userid}/capstone/simulations/videos/{model_num}/all_expected_predicted.avi'\n",
    "choppy_expected_predicted_video_path = f'/scratch/{userid}/capstone/simulations/videos/{model_num}/choppy_expected_predicted.avi'\n",
    "\n",
    "\n",
    "create_dir(input_images_path)\n",
    "create_dir(output_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [03:50<00:00,  1.76it/s]\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/scratch/ns4486/capstone/results/NUM-13.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-91e999c9e8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_outputs_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/scratch/ns4486/capstone/results/NUM-13.npy'"
     ]
    }
   ],
   "source": [
    "if run_through_model:\n",
    "\n",
    "    checkpoint_dir = f\"/scratch/ns4486/capstone/checkpoints/conv_ae/arch_2/AE_batch1/{model_num}/checkpoints/last.ckpt\"\n",
    "    data_path = '/scratch/ns4486/numerical-relativity-interpolation/Proca_fiducial_scaled_cropped.hdf5'\n",
    "\n",
    "    model = PlaceholderModel.load_from_checkpoint(checkpoint_dir, hparams = {}, data_path=data_path)\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    dataset = SingleChannelDataset(data_path)\n",
    "\n",
    "    outputs = None\n",
    "    inputs = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm.tqdm(range(len(dataset))):\n",
    "            x1 = dataset[i][0].unsqueeze(0)\n",
    "            x2 = dataset[i][1].unsqueeze(0)\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            z = model(x1, x2)\n",
    "            y_hat = model.decoder(z)\n",
    "\n",
    "            if inputs is None:\n",
    "                inputs = torch.cat((dataset[i][0], dataset[i][1]))\n",
    "                inputs = inputs.unsqueeze(0)\n",
    "            else:\n",
    "                t = torch.cat((dataset[i][0], dataset[i][1])).unsqueeze(0)\n",
    "                inputs = torch.cat((inputs, t))\n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = y_hat.cpu().squeeze(0).detach().numpy()\n",
    "            else:\n",
    "                outputs = np.concatenate((outputs, y_hat.cpu().squeeze(0).detach().numpy()), axis=0)\n",
    "\n",
    "    outputs = outputs.reshape((407, 1, 72, 72, 72))\n",
    "    inputs = np.array(inputs)\n",
    "\n",
    "    with open(inputs_outputs_save_path, 'wb') as f:\n",
    "        np.save(f, inputs)\n",
    "        np.save(f, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_input_images or generate_output_images:\n",
    "\n",
    "    with open(inputs_outputs_save_path, 'rb') as f:\n",
    "        inputs = np.load(f)\n",
    "        outputs = np.load(f)\n",
    "\n",
    "    new_input = inputs[:, 0, 35, :, :]\n",
    "    new_output = outputs[:, 0, 35, :, :]\n",
    "\n",
    "    cats = pd.qcut(new_input.flatten(), q=30)\n",
    "\n",
    "    color_interval_values = []\n",
    "    color = 1\n",
    "\n",
    "    for interval in list(cats.categories):\n",
    "        color_interval_values.append([interval.left, interval.right, color])\n",
    "        color += 1\n",
    "\n",
    "    color_intervals_df = pd.DataFrame(color_interval_values, columns=['left', 'right', 'color'])\n",
    "    color_intervals_df\n",
    "\n",
    "    def estimate_color(x):\n",
    "        for index, row in color_intervals_df.iterrows():\n",
    "            if x > row.left and x <= row.right:\n",
    "                return row.color\n",
    "        if x <= color_intervals_df.iloc[0]['left']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [32:00<00:00,  4.72s/it]\n"
     ]
    }
   ],
   "source": [
    "if generate_input_images:\n",
    "\n",
    "    for index in tqdm.tqdm(range(new_input.shape[0])):\n",
    "        location_value = []\n",
    "        frame = 0\n",
    "\n",
    "        for i in range(new_input[index].shape[0]):\n",
    "            for j in range(new_input[index].shape[1]):\n",
    "                location_value.append([i, j, new_input[index, i, j]])\n",
    "\n",
    "        df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "        df['color'] = df['value'].apply(estimate_color)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        plt.scatter(df['x'], df['y'], c=df['color'], vmin=1, vmax=30, s=80)\n",
    "        \n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.plot()\n",
    "\n",
    "        plt.savefig(os.path.join(input_images_path, f'{index}.png'), dpi = 50)\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [39:06<00:00,  5.77s/it]\n"
     ]
    }
   ],
   "source": [
    "if generate_output_images:\n",
    "\n",
    "    for index in tqdm.tqdm(range(new_output.shape[0])):\n",
    "        location_value = []\n",
    "        frame = 0\n",
    "\n",
    "        for i in range(new_output[index].shape[0]):\n",
    "            for j in range(new_output[index].shape[1]):\n",
    "                location_value.append([i, j, new_output[index, i, j]])\n",
    "\n",
    "        df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "        df['color'] = df['value'].apply(estimate_color)\n",
    "\n",
    "#         fig = px.scatter(df, x='x', y='y', color='color', range_color = [1, 30], color_continuous_scale='Viridis', width=800, height=800)\n",
    "\n",
    "#         fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "\n",
    "#         fig.write_image(os.path.join(output_images_path, f'{index}.png'), width=800, height=800)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        plt.scatter(df['x'], df['y'], c=df['color'], vmin=1, vmax=30, s=80)\n",
    "        \n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.plot()\n",
    "\n",
    "        plt.savefig(os.path.join(output_images_path, f'{index}.png'), dpi = 50)\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_videos:\n",
    "\n",
    "    original_images = [f'{i}.png' for i in range(407)]\n",
    "    original_images = original_images[1:]\n",
    "\n",
    "    predicted_images = [f'{i}.png' for i in range(407)]\n",
    "    predicted_images = predicted_images[:-1]\n",
    "\n",
    "\n",
    "    frame = cv2.imread(os.path.join(input_images_path, original_images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(all_expected_predicted_video_path, 0, 10, (width*2,height))\n",
    "\n",
    "    for i in range(len(original_images)):\n",
    "        # change on every other image\n",
    "        left_img = cv2.imread(os.path.join(input_images_path, original_images[i]))\n",
    "\n",
    "        right_img = cv2.imread(os.path.join(output_images_path, predicted_images[i]))\n",
    "\n",
    "        im_h = cv2.hconcat([left_img, right_img])\n",
    "\n",
    "        video.write(im_h)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "\n",
    "    original_images = [f'{i}.png' for i in range(407)]\n",
    "    predicted_images = [f'{i}.png' for i in range(407)]\n",
    "\n",
    "    frame = cv2.imread(os.path.join(input_images_path, original_images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(choppy_expected_predicted_video_path, 0, 10, (width*3,height))\n",
    "\n",
    "    for i in range(len(original_images)):\n",
    "        # change on every other image\n",
    "        if i % 2 == 0:\n",
    "            left_img = cv2.imread(os.path.join(input_images_path, original_images[i]))\n",
    "\n",
    "            right_img = left_img\n",
    "        else:\n",
    "            right_img = cv2.imread(os.path.join(output_images_path, predicted_images[i - 1]))\n",
    "\n",
    "        mid_img = cv2.imread(os.path.join(input_images_path, original_images[i]))\n",
    "\n",
    "        im_h = cv2.hconcat([left_img, mid_img, right_img])\n",
    "\n",
    "        video.write(im_h)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
