{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from models.conv3d_encdec.model import PlaceholderModel\n",
    "from models.conv3d_encdec.loader import SingleChannelDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_outputs_save_path = '/scratch/ns4486/capstone/results_num_10.npy'\n",
    "\n",
    "run_through_model = False\n",
    "generate_input_images = True\n",
    "input_images_path = '/scratch/ns4486/capstone/simulations/original_35th_frames'\n",
    "generate_output_images = True\n",
    "output_images_path = '/scratch/ns4486/capstone/simulations/predict_35th_frames_model_num_10/'\n",
    "generate_videos = True\n",
    "all_expected_predicted_video_path = '/scratch/ns4486/capstone/videos/all_expected_predicted.avi'\n",
    "choppy_expected_predicted_video_path = '/scratch/ns4486/capstone/videos/choppy_expected_predicted.avi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [08:26<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "if run_through_model:\n",
    "\n",
    "    checkpoint_dir = \"/scratch/ns4486/capstone/checkpoints/conv_ae/arch_2/AE_batch1/NUM-10/checkpoints/last.ckpt\"\n",
    "    data_path = '/scratch/ns4486/numerical-relativity-interpolation/Proca_fiducial_scaled_cropped.hdf5'\n",
    "\n",
    "    model = PlaceholderModel.load_from_checkpoint(checkpoint_dir, hparams = {}, data_path=data_path)\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    dataset = SingleChannelDataset(data_path)\n",
    "\n",
    "    outputs = None\n",
    "    inputs = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm.tqdm(range(len(dataset))):\n",
    "            x1 = dataset[i][0].unsqueeze(0)\n",
    "            x2 = dataset[i][1].unsqueeze(0)\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            z = model(x1, x2)\n",
    "            y_hat = model.decoder(z)\n",
    "\n",
    "            if inputs is None:\n",
    "                inputs = torch.cat((dataset[i][0], dataset[i][1]))\n",
    "                inputs = inputs.unsqueeze(0)\n",
    "            else:\n",
    "                t = torch.cat((dataset[i][0], dataset[i][1])).unsqueeze(0)\n",
    "                inputs = torch.cat((inputs, t))\n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = y_hat.cpu().squeeze(0).detach().numpy()\n",
    "            else:\n",
    "                outputs = np.concatenate((outputs, y_hat.cpu().squeeze(0).detach().numpy()), axis=0)\n",
    "\n",
    "    outputs = outputs.reshape((407, 1, 72, 72, 72))\n",
    "    inputs = np.array(inputs)\n",
    "\n",
    "    with open(inputs_outputs_save_path, 'wb') as f:\n",
    "        np.save(f, inputs)\n",
    "        np.save(f, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_input_images or generate_output_images:\n",
    "\n",
    "    with open(inputs_outputs_save_path, 'rb') as f:\n",
    "        inputs = np.load(f)\n",
    "        outputs = np.load(f)\n",
    "\n",
    "    new_input = inputs[:, 0, 35, :, :]\n",
    "    new_output = outputs[:, 0, 35, :, :]\n",
    "\n",
    "    cats = pd.qcut(new_input.flatten(), q=30)\n",
    "\n",
    "    color_interval_values = []\n",
    "    color = 1\n",
    "\n",
    "    for interval in list(cats.categories):\n",
    "        color_interval_values.append([interval.left, interval.right, color])\n",
    "        color += 1\n",
    "\n",
    "    color_intervals_df = pd.DataFrame(color_interval_values, columns=['left', 'right', 'color'])\n",
    "    color_intervals_df\n",
    "\n",
    "    def estimate_color(x):\n",
    "        for index, row in color_intervals_df.iterrows():\n",
    "            if x > row.left and x <= row.right:\n",
    "                return row.color\n",
    "        if x <= color_intervals_df.iloc[0]['left']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js\n"
     ]
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "print(pio.orca.config.plotlyjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nThe orca executable is required in order to export figures as static images,\nbut the executable that was found at '/ext3/miniconda3/bin/orca'\ndoes not seem to be a valid plotly orca executable. Please refer to the end of\nthis message for details on what went wrong.\n\nIf you haven't installed orca yet, you can do so using conda as follows:\n\n    $ conda install -c plotly plotly-orca\n\nAlternatively, see other installation methods in the orca project README at\nhttps://github.com/plotly/orca\n\nAfter installation is complete, no further configuration should be needed.\n\nIf you have installed orca, then for some reason plotly.py was unable to\nlocate it. In this case, set the `plotly.io.orca.config.executable`\nproperty to the full path of your orca executable. For example:\n\n    >>> plotly.io.orca.config.executable = '/path/to/orca'\n\nAfter updating this executable property, try the export operation again.\nIf it is successful then you may want to save this configuration so that it\nwill be applied automatically in future sessions. You can do this as follows:\n\n    >>> plotly.io.orca.config.save()\n\nIf you're still having trouble, feel free to ask for help on the forums at\nhttps://community.plot.ly/c/api/python\n\nHere is the error that was returned by the command\n    $ /ext3/miniconda3/bin/orca --help\n\n[Return code: 1]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e92142a1074e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'markers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_images_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{index}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m#         fig.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3278\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0;31m# Static helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# -------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# Do this first so we don't create a file if image conversion fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     img_data = to_image(\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_orca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_image\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mto_image_orca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         return to_image_orca(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;31m# Make sure orca sever is running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     \u001b[0mensure_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[0;31m# Handle defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mensure_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0;31m# Validate orca executable only if server_url is not provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"unvalidated\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m             \u001b[0mvalidate_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m         \u001b[0;31m# Acquire lock to make sure that we keep the properties of orca_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# consistent across threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mvalidate_executable\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mon\u001b[0m \u001b[0mXvfb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m \"\"\"\n\u001b[0;32m-> 1184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhelp_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nThe orca executable is required in order to export figures as static images,\nbut the executable that was found at '/ext3/miniconda3/bin/orca'\ndoes not seem to be a valid plotly orca executable. Please refer to the end of\nthis message for details on what went wrong.\n\nIf you haven't installed orca yet, you can do so using conda as follows:\n\n    $ conda install -c plotly plotly-orca\n\nAlternatively, see other installation methods in the orca project README at\nhttps://github.com/plotly/orca\n\nAfter installation is complete, no further configuration should be needed.\n\nIf you have installed orca, then for some reason plotly.py was unable to\nlocate it. In this case, set the `plotly.io.orca.config.executable`\nproperty to the full path of your orca executable. For example:\n\n    >>> plotly.io.orca.config.executable = '/path/to/orca'\n\nAfter updating this executable property, try the export operation again.\nIf it is successful then you may want to save this configuration so that it\nwill be applied automatically in future sessions. You can do this as follows:\n\n    >>> plotly.io.orca.config.save()\n\nIf you're still having trouble, feel free to ask for help on the forums at\nhttps://community.plot.ly/c/api/python\n\nHere is the error that was returned by the command\n    $ /ext3/miniconda3/bin/orca --help\n\n[Return code: 1]\n\n"
     ]
    }
   ],
   "source": [
    "if generate_input_images:\n",
    "\n",
    "    for index in tqdm.tqdm(range(new_input.shape[0])):\n",
    "        location_value = []\n",
    "        frame = 0\n",
    "\n",
    "        for i in range(new_input[index].shape[0]):\n",
    "            for j in range(new_input[index].shape[1]):\n",
    "                location_value.append([i, j, new_input[index, i, j]])\n",
    "\n",
    "        df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "        df['color'] = df['value'].apply(estimate_color)\n",
    "\n",
    "        fig = px.scatter(df, x='x', y='y', color='color', range_color = [1, 30], color_continuous_scale='Viridis', width=800, height=800)\n",
    "\n",
    "        fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "\n",
    "        fig.write_image(os.path.join(input_images_path, f'{index}.png'), width=800, height=800)\n",
    "#         fig.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_output_images:\n",
    "\n",
    "    for index in tqdm.tqdm(range(new_output.shape[0])):\n",
    "        location_value = []\n",
    "        frame = 0\n",
    "\n",
    "        for i in range(new_output[index].shape[0]):\n",
    "            for j in range(new_output[index].shape[1]):\n",
    "                location_value.append([i, j, new_output[index, i, j]])\n",
    "\n",
    "        df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "        df['color'] = df['value'].apply(estimate_color)\n",
    "\n",
    "        fig = px.scatter(df, x='x', y='y', color='color', range_color = [1, 30], color_continuous_scale='Viridis', width=800, height=800)\n",
    "\n",
    "        fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "\n",
    "        fig.write_image(os.path.join(output_images_path, f'{index}.png'), width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_videos:\n",
    "\n",
    "    original_images = [f'{i}.png' for i in range(407)]\n",
    "    original_images = original_images[1:]\n",
    "\n",
    "    predicted_images = [f'{i}.png' for i in range(407)]\n",
    "    predicted_images = predicted_images[:-1]\n",
    "\n",
    "\n",
    "    frame = cv2.imread(os.path.join(input_images_path, original_images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(all_expected_predicted_video_path, 0, 10, (width*2,height))\n",
    "\n",
    "    for i in range(len(original_images)):\n",
    "        # change on every other image\n",
    "        left_img = cv2.imread(os.path.join(input_images_path, original_images[i]))\n",
    "\n",
    "        right_img = cv2.imread(os.path.join(output_images_path, predicted_images[i]))\n",
    "\n",
    "        im_h = cv2.hconcat([left_img, right_img])\n",
    "\n",
    "        video.write(im_h)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "\n",
    "    original_images = [f'{i}.png' for i in range(407)]\n",
    "    predicted_images = [f'{i}.png' for i in range(407)]\n",
    "\n",
    "    frame = cv2.imread(os.path.join(input_images_path, original_images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(choppy_expected_predicted_video_path, 0, 10, (width*3,height))\n",
    "\n",
    "    for i in range(len(original_images)):\n",
    "        # change on every other image\n",
    "        if i % 2 == 0:\n",
    "            left_img = cv2.imread(os.path.join(input_images_path, original_images[i]))\n",
    "\n",
    "            right_img = left_img\n",
    "        else:\n",
    "            right_img = cv2.imread(os.path.join(output_images_path, predicted_images[i - 1]))\n",
    "\n",
    "        mid_img = cv2.imread(os.path.join(input_images_path, original_images[i]))\n",
    "\n",
    "        im_h = cv2.hconcat([left_img, mid_img, right_img])\n",
    "\n",
    "        video.write(im_h)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
