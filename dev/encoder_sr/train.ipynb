{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'encoder' from '/Users/paramshah/Documents/Param/NYU/courses/Capstone Project/repo/numerical-relativity-interpolation/dev/encoder_sr/encoder.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from gaussian_ring_grid_generator import GaussianRingSpaceTimeGrid\n",
    "import encoder\n",
    "import importlib\n",
    "importlib.reload(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paramshah/Documents/Param/NYU/courses/Capstone Project/repo/numerical-relativity-interpolation/dev/encoder_sr/gaussian_ring_grid_generator.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(GaussianRing(self.space_grid.cpu(), i, i/2)).unsqueeze(0) for i in self.time_axis]\n"
     ]
    }
   ],
   "source": [
    "spaceTimeContext = GaussianRingSpaceTimeGrid(\n",
    "    n_space_grid = 32,\n",
    "    n_time_grid = 5,\n",
    "    space_min_x = -5,\n",
    "    space_max_x = 5,\n",
    "    time_min_t = 0.5,\n",
    "    time_max_t = 2.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 32, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceTimeContext.values.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000, 2.0000, 2.5000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceTimeContext.time_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grid = GaussianRingSpaceTimeGrid(\n",
    "    n_space_grid = 48,\n",
    "    n_time_grid = 4,\n",
    "    space_min_x = -5,\n",
    "    space_max_x = 5,\n",
    "    time_min_t = 0.75,\n",
    "    time_max_t = 2.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7500, 1.2500, 1.7500, 2.2500])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grid.time_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 48, 48, 48])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grid.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decimal_index(axis_values, value):\n",
    "    closest_above = axis_values[axis_values >= value].min()\n",
    "    closest_below = axis_values[axis_values <= value].max()\n",
    "    index_below = np.where(axis_values == closest_below)[0][0]\n",
    "    \n",
    "    if closest_above == closest_below:\n",
    "        return index_below\n",
    "    \n",
    "    return index_below + ((value - closest_below)/(closest_above - closest_below))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_decimal_index(spaceTimeContext.time_axis.cpu().numpy(), 2.2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = []\n",
    "xs = []\n",
    "ys = []\n",
    "zs = []\n",
    "\n",
    "vals = []\n",
    "\n",
    "for i in range(train_grid.values.shape[0]):\n",
    "    t = get_decimal_index(spaceTimeContext.time_axis.cpu().numpy(), train_grid.time_axis[i].item())\n",
    "    \n",
    "    for j in range(train_grid.values.shape[2]):\n",
    "        x = get_decimal_index(spaceTimeContext.space_axis.cpu().numpy(), train_grid.space_axis[j].item())\n",
    "        \n",
    "        for k in range(train_grid.values.shape[3]):\n",
    "            y = get_decimal_index(spaceTimeContext.space_axis.cpu().numpy(), train_grid.space_axis[k].item())\n",
    "            \n",
    "            for l in range(train_grid.values.shape[4]):\n",
    "                z = get_decimal_index(spaceTimeContext.space_axis.cpu().numpy(), train_grid.space_axis[l].item())\n",
    "                \n",
    "                ts.append(t)\n",
    "                xs.append(x)\n",
    "                ys.append(y)\n",
    "                zs.append(z)\n",
    "                vals.append(train_grid.values[i, 0, j, k, l].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(vals, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442368, 4), (442368,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = np.array([ts, xs, ys, zs]).T\n",
    "outs = np.array(vals)\n",
    "inps.shape, outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([442368, 1, 4]), torch.Size([442368, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.Tensor(inps).unsqueeze(1)\n",
    "output_tensor = torch.Tensor(outs).unsqueeze(1)\n",
    "input_tensor.shape, output_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(input_tensor,output_tensor) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=`, shuffle=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = encoder.SR(1, 16, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:17,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:30, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:41, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:55, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:04, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [01:13, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:22,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:32,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [01:42,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [01:52, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [02:01,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([32768, 1, 4])\n",
      "torch.Size([32768, 1])\n",
      "torch.Size([32768, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:10,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 32, 32])\n",
      "torch.Size([16384, 1, 4])\n",
      "torch.Size([16384, 1])\n",
      "torch.Size([16384, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [02:16,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss = 38892.905305044995\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(0, 100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm.tqdm(enumerate(train_dataloader, 0)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(spaceTimeContext.values, inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    torch.save(model.state_dict(), f'/scratch/prs392/capstone/checkpoints/encoder_sr/epoch={epoch}.pt')\n",
    "    \n",
    "    print(f\"epoch {epoch} loss = {running_loss/(i+1)}\")\n",
    "    losses.append(running_loss/(i+1))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
