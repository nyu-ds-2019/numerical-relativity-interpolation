{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilvs/anaconda3/envs/dl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from loader import SingleChannelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            in_channels = 1,\n",
    "            out_channels = 8,\n",
    "            kernel_size = (3, 3, 3),\n",
    "            stride = (1, 1, 1),\n",
    "            padding = (1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool3d(\n",
    "            kernel_size = (2, 2, 2),\n",
    "            stride = (2, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(\n",
    "            in_channels = 8,\n",
    "            out_channels = 16,\n",
    "            kernel_size = (3, 3, 3),\n",
    "            stride = (1, 1, 1),\n",
    "            padding = (1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool3d(\n",
    "            kernel_size = (3, 3, 3),\n",
    "            stride = (2, 2, 2),\n",
    "            padding = (1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(\n",
    "            in_channels = 16,\n",
    "            out_channels = 32,\n",
    "            kernel_size = (3, 3, 3),\n",
    "            stride = (1, 1, 1),\n",
    "            padding = (1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.maxpool3 = nn.MaxPool3d(\n",
    "            kernel_size = (2, 2, 2),\n",
    "            stride = (2, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm3d(8, affine = True)\n",
    "        self.bn2 = nn.BatchNorm3d(16, affine = True)\n",
    "        self.bn3 = nn.BatchNorm3d(32, affine = True)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.upsample3 = nn.Upsample(\n",
    "            scale_factor = 2,\n",
    "            mode = 'nearest'\n",
    "        )\n",
    "        \n",
    "        self.conv3_r = nn.Conv3d(\n",
    "            in_channels = 32,\n",
    "            out_channels = 16,\n",
    "            kernel_size = (3, 3, 3),\n",
    "            stride = (1, 1, 1),\n",
    "            padding = (1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.upsample2 = nn.Upsample(\n",
    "            scale_factor = 2,\n",
    "            mode = 'nearest'\n",
    "        )\n",
    "        \n",
    "        self.conv2_r = nn.Conv3d(\n",
    "            in_channels = 16,\n",
    "            out_channels = 8,\n",
    "            kernel_size = (3, 3, 3),\n",
    "            stride = (1, 1, 1),\n",
    "            padding = (1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.upsample1 = nn.Upsample(\n",
    "            scale_factor = 2,\n",
    "            mode = 'nearest'\n",
    "        )\n",
    "        \n",
    "        self.conv1_r = nn.Conv3d(\n",
    "            in_channels = 8,\n",
    "            out_channels = 1,\n",
    "            kernel_size = (3, 3, 3),\n",
    "            stride = (1, 1, 1),\n",
    "            padding = (1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.bn3_r = nn.BatchNorm3d(16, affine = True)\n",
    "        self.bn2_r = nn.BatchNorm3d(8, affine = True)\n",
    "        self.bn1_r = nn.BatchNorm3d(1, affine = True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.upsample3(x)\n",
    "        x = F.relu(self.conv3_r(x))\n",
    "        x = self.bn3_r(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = F.relu(self.conv2_r(x))\n",
    "        x = self.bn2_r(x)\n",
    "        x = self.upsample1(x)\n",
    "        x = F.relu(self.conv1_r(x))\n",
    "        x = self.bn1_r(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 8, 72, 72, 72]             224\n",
      "       BatchNorm3d-2        [-1, 8, 72, 72, 72]              16\n",
      "         MaxPool3d-3        [-1, 8, 36, 36, 36]               0\n",
      "            Conv3d-4       [-1, 16, 36, 36, 36]           3,472\n",
      "       BatchNorm3d-5       [-1, 16, 36, 36, 36]              32\n",
      "         MaxPool3d-6       [-1, 16, 18, 18, 18]               0\n",
      "            Conv3d-7       [-1, 32, 18, 18, 18]          13,856\n",
      "       BatchNorm3d-8       [-1, 32, 18, 18, 18]              64\n",
      "         MaxPool3d-9          [-1, 32, 9, 9, 9]               0\n",
      "         Upsample-10       [-1, 32, 18, 18, 18]               0\n",
      "           Conv3d-11       [-1, 16, 18, 18, 18]          13,840\n",
      "      BatchNorm3d-12       [-1, 16, 18, 18, 18]              32\n",
      "         Upsample-13       [-1, 16, 36, 36, 36]               0\n",
      "           Conv3d-14        [-1, 8, 36, 36, 36]           3,464\n",
      "      BatchNorm3d-15        [-1, 8, 36, 36, 36]              16\n",
      "         Upsample-16        [-1, 8, 72, 72, 72]               0\n",
      "           Conv3d-17        [-1, 1, 72, 72, 72]             217\n",
      "      BatchNorm3d-18        [-1, 1, 72, 72, 72]               2\n",
      "================================================================\n",
      "Total params: 35,235\n",
      "Trainable params: 35,235\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.42\n",
      "Forward/backward pass size (MB): 106.25\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 107.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(encoder, (1, 72, 72, 72))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "          Upsample-1       [-1, 32, 18, 18, 18]               0\n",
      "            Conv3d-2       [-1, 16, 18, 18, 18]          13,840\n",
      "       BatchNorm3d-3       [-1, 16, 18, 18, 18]              32\n",
      "          Upsample-4       [-1, 16, 36, 36, 36]               0\n",
      "            Conv3d-5        [-1, 8, 36, 36, 36]           3,464\n",
      "       BatchNorm3d-6        [-1, 8, 36, 36, 36]              16\n",
      "          Upsample-7        [-1, 8, 72, 72, 72]               0\n",
      "            Conv3d-8        [-1, 1, 72, 72, 72]             217\n",
      "       BatchNorm3d-9        [-1, 1, 72, 72, 72]               2\n",
      "================================================================\n",
      "Total params: 17,571\n",
      "Trainable params: 17,571\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 42.71\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 42.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(decoder, (32, 9, 9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
