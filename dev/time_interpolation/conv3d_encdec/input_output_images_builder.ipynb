{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_num_19.npy', 'rb') as f:\n",
    "    inputs = np.load(f)\n",
    "    outputs = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((407, 2, 72, 72, 72), (407, 1, 72, 72, 72))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, 72, 72)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = inputs[:, 0, 35, :, :]\n",
    "new_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, 72, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_output = outputs[:, 0, 35, :, :]\n",
    "new_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.qcut(new_input.flatten(), q=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_interval_values = []\n",
    "color = 1\n",
    "# i = 1\n",
    "for interval in list(cats.categories):\n",
    "    color_interval_values.append([interval.left, interval.right, color])\n",
    "#     if i % 2 == 0:\n",
    "    color += 1\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.00100</td>\n",
       "      <td>0.00273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00273</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00453</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00453</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.00613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00613</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.00785</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00785</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.00980</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00980</td>\n",
       "      <td>0.01090</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01090</td>\n",
       "      <td>0.01210</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01210</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.01640</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01640</td>\n",
       "      <td>0.01820</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01820</td>\n",
       "      <td>0.02030</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.02030</td>\n",
       "      <td>0.02270</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.02270</td>\n",
       "      <td>0.02560</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.02560</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.03290</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.03290</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.04350</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.04350</td>\n",
       "      <td>0.05060</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.05060</td>\n",
       "      <td>0.05950</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.05950</td>\n",
       "      <td>0.07050</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.07050</td>\n",
       "      <td>0.08490</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.08490</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.10500</td>\n",
       "      <td>0.13500</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.13500</td>\n",
       "      <td>0.19000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.19000</td>\n",
       "      <td>12.81900</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       left     right  color\n",
       "0  -0.00100   0.00273      1\n",
       "1   0.00273   0.00370      2\n",
       "2   0.00370   0.00453      3\n",
       "3   0.00453   0.00533      4\n",
       "4   0.00533   0.00613      5\n",
       "5   0.00613   0.00696      6\n",
       "6   0.00696   0.00785      7\n",
       "7   0.00785   0.00879      8\n",
       "8   0.00879   0.00980      9\n",
       "9   0.00980   0.01090     10\n",
       "10  0.01090   0.01210     11\n",
       "11  0.01210   0.01340     12\n",
       "12  0.01340   0.01480     13\n",
       "13  0.01480   0.01640     14\n",
       "14  0.01640   0.01820     15\n",
       "15  0.01820   0.02030     16\n",
       "16  0.02030   0.02270     17\n",
       "17  0.02270   0.02560     18\n",
       "18  0.02560   0.02900     19\n",
       "19  0.02900   0.03290     20\n",
       "20  0.03290   0.03770     21\n",
       "21  0.03770   0.04350     22\n",
       "22  0.04350   0.05060     23\n",
       "23  0.05060   0.05950     24\n",
       "24  0.05950   0.07050     25\n",
       "25  0.07050   0.08490     26\n",
       "26  0.08490   0.10500     27\n",
       "27  0.10500   0.13500     28\n",
       "28  0.13500   0.19000     29\n",
       "29  0.19000  12.81900     30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_intervals_df = pd.DataFrame(color_interval_values, columns=['left', 'right', 'color'])\n",
    "color_intervals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_color(x):\n",
    "    for index, row in color_intervals_df.iterrows():\n",
    "        if x > row.left and x <= row.right:\n",
    "            return row.color\n",
    "    if x <= color_intervals_df.iloc[0]['left']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_value = []\n",
    "# frame = 0\n",
    "# index = 1\n",
    "\n",
    "# for i in range(new_input[index].shape[0]):\n",
    "#     for j in range(new_input[index].shape[1]):\n",
    "#         location_value.append([i, j, new_input[index, i, j]])\n",
    "\n",
    "# df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "# # df = df[df['value']>0.1]\n",
    "\n",
    "# df['color'] = df['value'].apply(estimate_color)\n",
    "\n",
    "# fig = px.scatter(df, x='x', y='y', color='color', range_color = [1, 30], color_continuous_scale='Viridis', width=800, height=800)\n",
    "\n",
    "# fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_value = []\n",
    "# frame = 0\n",
    "# index = 0\n",
    "\n",
    "# for i in range(new_output[index].shape[0]):\n",
    "#     for j in range(new_output[index].shape[1]):\n",
    "#         location_value.append([i, j, new_output[index, i, j]])\n",
    "\n",
    "# df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "# # df = df[df['value']>0.1]\n",
    "\n",
    "# df['color'] = df['value'].apply(estimate_color)\n",
    "\n",
    "# fig = px.scatter(df, x='x', y='y', color='color', range_color = [1, 30], color_continuous_scale='Viridis', width=800, height=800)\n",
    "\n",
    "# fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(index):\n",
    "    print(\"Entering process \", index)\n",
    "    location_value = []\n",
    "    frame = 0\n",
    "\n",
    "    for i in range(new_output[index].shape[0]):\n",
    "        for j in range(new_output[index].shape[1]):\n",
    "            location_value.append([i, j, new_output[index, i, j]])\n",
    "\n",
    "    df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "    # df = df[df['value']>0.1]\n",
    "\n",
    "    df['color'] = df['value'].apply(estimate_color)\n",
    "\n",
    "    fig = px.scatter(df, x='x', y='y', color='color', range_color = [1, 30], color_continuous_scale='Viridis', width=800, height=800)\n",
    "\n",
    "    fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "\n",
    "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
    "    \n",
    "    print(\"Exiting process \", index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in tqdm.tqdm(range(new_output.shape[0])):\n",
    "#     location_value = []\n",
    "#     frame = 0\n",
    "\n",
    "#     for i in range(new_output[index].shape[0]):\n",
    "#         for j in range(new_output[index].shape[1]):\n",
    "#             location_value.append([i, j, new_output[index, i, j]])\n",
    "\n",
    "#     df = pd.DataFrame(data = location_value, columns=['x', 'y', 'value'])\n",
    "\n",
    "#     # df = df[df['value']>0.1]\n",
    "\n",
    "#     df['color'] = df['value'].apply(estimate_color)\n",
    "\n",
    "#     fig = px.scatter(df, x='x', y='y', color='color', range_color = [1, 30], color_continuous_scale='Viridis', width=800, height=800)\n",
    "\n",
    "#     fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "\n",
    "#     fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_num19_output/{index}.png', width=800, height=800)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/407 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/407 [00:00<00:22, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entering process  0Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/407 [00:00<00:21, 18.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "Entering process \n",
      " 2Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 6/407 [00:00<00:26, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/407 [00:00<00:35, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/407 [00:00<00:47,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/407 [00:00<00:58,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/407 [00:01<00:53,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process 8\n",
      " \n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (94784) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "1it [00:57, 57.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (95301) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  2\n",
      "Exiting process  3\n",
      "Exiting process  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:52, 57.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "Exiting process  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:54, 40.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 4 done\n",
      "Exiting process  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:58, 29.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n",
      "thread 6 done\n",
      "Exiting process  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:59, 20.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 7 done\n",
      "Exiting process  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:59, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  9\n",
      "thread 8 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:00, 12.02s/it]\n",
      "  0%|          | 0/397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/397 [00:00<00:17, 22.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10Entering process \n",
      "11 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 5/397 [00:00<00:19, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/397 [00:00<00:26, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 13Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/397 [00:00<00:36, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "14 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/397 [00:00<00:46,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/397 [00:00<00:57,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 16Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/397 [00:01<00:51,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "17"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "18 \n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (96846) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (97577) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (97834) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:09, 129.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "Exiting process  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:11, 91.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "Exiting process  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:12, 64.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 3 done\n",
      "Exiting process  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:13, 45.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 4 done\n",
      "Exiting process  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:13, 31.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n",
      "Exiting process  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:14, 22.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 6 done\n",
      "Exiting process  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:15, 13.52s/it]\n",
      "  0%|          | 0/387 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/387 [00:00<00:17, 22.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20Entering process 21\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 5/387 [00:00<00:18, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/387 [00:00<00:25, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/387 [00:00<00:34, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/387 [00:00<00:48,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/387 [00:00<00:58,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/387 [00:01<00:50,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "27"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "28 \n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (99032) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (99100) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (99236) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (99704) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  26\n",
      "Exiting process  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:17, 137.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "Exiting process  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:18, 96.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "Exiting process  25\n",
      "Exiting process  28\n",
      "Exiting process  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:18, 13.89s/it]\n",
      "  0%|          | 0/377 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/377 [00:00<00:16, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30Entering process 31\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 5/377 [00:00<00:18, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/377 [00:00<00:29, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/377 [00:00<00:38,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "34Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/377 [00:00<00:46,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "35 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/377 [00:00<00:58,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "36Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/377 [00:01<00:50,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "37"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "38 \n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-32:\n",
      "Traceback (most recent call last):\n",
      "Process Process-35:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (101497) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (101501) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "Process Process-39:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (102063) - No such process\n",
      "\n",
      "        \n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (102114) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process Exiting process   3335\n",
      "\n",
      "Exiting process  32\n",
      "Exiting process  36\n",
      "Exiting process Exiting process   3730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:18, 13.85s/it]\n",
      "  0%|          | 0/367 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/367 [00:00<00:16, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40Entering process 41\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 5/367 [00:00<00:19, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/367 [00:00<00:27, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "43 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/367 [00:00<00:35, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "44Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/367 [00:00<00:44,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "45 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/367 [00:00<00:55,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 9/367 [00:01<00:49,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "48 \n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "Process Process-50:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (103699) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (103740) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  40\n",
      "Exiting process  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:32, 152.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:32, 106.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  42\n",
      "thread 1 done\n",
      "Exiting process  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:33, 74.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43Exiting process \n",
      " 44\n",
      "thread 2 done\n",
      "Exiting process  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [02:33, 36.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "Exiting process  46\n",
      "Exiting process  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:34, 15.44s/it]\n",
      "  0%|          | 0/357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/357 [00:00<00:15, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50Entering process 51\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 5/357 [00:00<00:18, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "52 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/357 [00:00<00:27, 12.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/357 [00:00<00:36,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/357 [00:00<00:50,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/357 [00:01<00:58,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "56Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/357 [00:01<00:49,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "57"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "58 \n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-58:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (105897) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-56:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (105929) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-54:\n",
      "Process Process-53:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (105985) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (105983) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-51:\n",
      "Process Process-60:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (106428) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (106430) - No such process\n",
      "\n",
      "        \n",
      "1it [01:36, 96.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "Exiting process  54\n",
      "Exiting process  56\n",
      "Exiting process  Exiting process 51 \n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:06, 12.64s/it]\n",
      "  0%|          | 0/347 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/347 [00:00<00:22, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entering process  60Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/347 [00:00<00:20, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      " Entering process \n",
      "62 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/347 [00:00<00:23, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "63Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/347 [00:00<00:31, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/347 [00:00<00:40,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/347 [00:00<00:52,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/347 [00:01<00:46,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "68 \n",
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-62:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "Process Process-61:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "Process Process-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (107658) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "Process Process-64:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (107699) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (107705) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (107757) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "1it [01:30, 90.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-66:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (108140) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  66\n",
      "Exiting process  67\n",
      "Exiting process Exiting process   6864\n",
      "\n",
      "Exiting process  69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:13, 13.37s/it]\n",
      "  0%|          | 0/337 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/337 [00:00<00:19, 16.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entering process  70Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/337 [00:00<00:18, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      " Entering process 72\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/337 [00:00<00:22, 14.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/337 [00:00<00:29, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "74Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/337 [00:00<00:39,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/337 [00:00<00:49,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "76Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/337 [00:01<00:44,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "78 \n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-75:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (109341) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-74:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-73:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "Process Process-79:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (109388) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (109393) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (109433) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-80:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (109902) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:21, 141.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "Exiting process  71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:22, 99.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "Exiting process  77\n",
      "Exiting process  76\n",
      "Exiting process  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:23, 14.38s/it]\n",
      "  0%|          | 0/327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/327 [00:00<00:25, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entering process 80 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/327 [00:00<00:25, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/327 [00:00<00:28, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 82Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/327 [00:00<00:34,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/327 [00:00<00:40,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "84Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 8/327 [00:00<00:50,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 85Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/327 [00:01<00:59,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 86Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/327 [00:01<00:56,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "87 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process 88\n",
      " \n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-87:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-83:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-86:\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (111250) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (111291) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (111320) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-84:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (111752) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  89\n",
      "Exiting process  80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:25, 145.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  88thread 0 done\n",
      "\n",
      "Exiting process  87\n",
      "Exiting process  81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:26, 102.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:27, 14.70s/it]\n",
      "  0%|          | 0/317 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/317 [00:00<00:20, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entering process  90Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 4/317 [00:00<00:18, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      " Entering process \n",
      "92 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/317 [00:00<00:20, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/317 [00:00<00:27, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/317 [00:00<00:38,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/317 [00:00<00:49,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 96Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/317 [00:01<00:44,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 97"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "98 \n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-92:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (113113) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-96:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "Process Process-100:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (113235) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (113266) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-99:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (113723) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:20, 140.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "Exiting process  92\n",
      "Exiting process  93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:20, 98.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:20, 68.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94\n",
      "thread 2 done\n",
      "thread 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:21, 48.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 4 done\n",
      "thread 5 done\n",
      "Exiting process  97\n",
      "Exiting process  96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:21, 14.17s/it]\n",
      "  0%|          | 0/307 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/307 [00:00<00:13, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100Entering process \n",
      " 101Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/307 [00:00<00:14, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/307 [00:00<00:20, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 103Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/307 [00:00<00:26, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 104\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/307 [00:00<00:35,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "105 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/307 [00:00<00:44,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "106 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/307 [00:01<00:39,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "108 \n",
      "109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-102:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (115168) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-108:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (115213) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-104:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (115288) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-110:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (115804) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:22, 142.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "Exiting process  102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:23, 100.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 2 done\n",
      "thread 3 done\n",
      "Exiting process  106\n",
      "Exiting process Exiting process   104108\n",
      "\n",
      "Exiting process  105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:25, 70.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:25, 14.52s/it]\n",
      "  0%|          | 0/297 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/297 [00:00<00:13, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 110Entering process 111\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/297 [00:00<00:14, 20.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      " Entering process \n",
      "113 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/297 [00:00<00:20, 13.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "114 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/297 [00:00<00:34,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/297 [00:00<00:42,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 116\n",
      "Entering process  \n",
      "117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/297 [00:01<00:41,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "118Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-112:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "Process Process-115:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (117331) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (117334) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-119:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (117496) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-116:\n",
      "Process Process-120:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (117902) - No such process\n",
      "\n",
      "        \n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (117906) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  113\n",
      "Exiting process  112\n",
      "Exiting process  117\n",
      "Exiting process  116\n",
      "Exiting process  110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:26, 14.67s/it]\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/287 [00:00<00:12, 22.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 120Entering process 121\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/287 [00:00<00:13, 20.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/287 [00:00<00:18, 14.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/287 [00:00<00:24, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 124\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/287 [00:00<00:33,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "125 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/287 [00:00<00:41,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "126 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/287 [00:01<00:36,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "128 \n",
      "129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-122:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (119294) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-129:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (119423) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-127:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (119496) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  122\n",
      "Exiting process  120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:44, 164.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "thread 2 done\n",
      "Exiting process  123\n",
      "Exiting process  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:45, 115.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "thread 3 done\n",
      "Exiting process  124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:46, 81.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  125\n",
      "thread 4 done\n",
      "Exiting process  127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:46, 16.70s/it]\n",
      "  0%|          | 0/277 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/277 [00:00<00:26, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/277 [00:00<00:29,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 4/277 [00:00<00:33,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "131 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/277 [00:00<00:39,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "132 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/277 [00:00<00:40,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 133\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/277 [00:01<00:42,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/277 [00:01<00:50,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 135\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/277 [00:01<01:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "136Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/277 [00:01<00:56,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "138 \n",
      "139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-135:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (122504) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-136:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (122609) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-139:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (123070) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  130\n",
      "Exiting process  131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:40, 160.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "Exiting process  136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:40, 112.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "thread 1 done\n",
      "Exiting process  137\n",
      "Exiting process  139Exiting process \n",
      " 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:42, 79.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:42, 16.24s/it]\n",
      "  0%|          | 0/267 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/267 [00:00<00:12, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 140Entering process \n",
      "141 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/267 [00:00<00:13, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/267 [00:00<00:19, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "143Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/267 [00:00<00:26,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 144\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/267 [00:00<00:32,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/267 [00:00<00:42,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/267 [00:01<00:36,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "148 \n",
      "149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-147:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "Process Process-144:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (125249) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "Process Process-142:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "Process Process-145:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (125274) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (125310) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (125315) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-150:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (126337) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:30, 150.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "Exiting process  147\n",
      "Exiting process  148\n",
      "Exiting process  142\n",
      "Exiting process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:31, 105.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:31, 15.18s/it]\n",
      "  0%|          | 0/257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/257 [00:00<00:11, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 150Entering process \n",
      "151 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/257 [00:00<00:12, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "152 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/257 [00:00<00:16, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/257 [00:00<00:26,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "154Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/257 [00:00<00:32,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 9/257 [00:00<00:38,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "156Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 9/257 [00:01<00:33,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "158 \n",
      "159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-151:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (127550) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "1it [01:34, 94.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-155:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (127632) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-158:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (128220) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  152\n",
      "Exiting process  153\n",
      "Exiting process  151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:36, 84.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "Exiting process  155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:37, 59.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n",
      "Exiting process  Exiting process 156 Exiting process \n",
      "159 \n",
      "158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:38, 15.82s/it]\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/247 [00:00<00:10, 22.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 160Entering process \n",
      "161 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/247 [00:00<00:11, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/247 [00:00<00:15, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "163Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/247 [00:00<00:21, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 164\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/247 [00:00<00:28,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 9/247 [00:00<00:35,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 166Entering process \n",
      " 167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 9/247 [00:01<00:32,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "168Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-170:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (129794) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-163:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (129838) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-167:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (129908) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-166:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (130398) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  163\n",
      "Exiting process  164\n",
      "Exiting process  168\n",
      "Exiting process  167\n",
      "Exiting process  160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:29, 149.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:29, 14.97s/it]\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 3/237 [00:00<00:10, 22.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 170Entering process 171\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/237 [00:00<00:11, 20.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/237 [00:00<00:14, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "173Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/237 [00:00<00:26,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 174Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/237 [00:00<00:32,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/237 [00:00<00:37,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/237 [00:01<00:33,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "178 \n",
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-177:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (131863) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-174:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (131934) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-180:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (132387) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  170\n",
      "Exiting process  171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:35, 155.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:35, 108.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "Exiting process  175\n",
      "Exiting process  172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:36, 76.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  174\n",
      "thread 2 done\n",
      "thread 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:37, 53.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  177\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "Exiting process  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:37, 37.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:37, 15.74s/it]\n",
      "  0%|          | 0/227 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 3/227 [00:00<00:13, 17.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 180Entering process 181\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/227 [00:00<00:13, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/227 [00:00<00:16, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "183Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/227 [00:00<00:20, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "184 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 8/227 [00:00<00:29,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "185Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/227 [00:01<00:38,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 \n",
      "Entering process \n",
      "187 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/227 [00:01<00:34,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "188Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-182:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (134133) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-187:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bd9cb80>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=32947): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bd9cb80>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=32947): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bd9cb80>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 32947\n",
      "    pid: 134708\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '32947', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process Exiting process   185187Exiting process \n",
      "\n",
      " 188\n",
      "Exiting process  180\n",
      "Exiting process  184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:50, 170.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "Exiting process  182\n",
      "Exiting process  189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:51, 119.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting process  183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:51, 17.17s/it]\n",
      "  0%|          | 0/217 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 3/217 [00:00<00:09, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 190Entering process 191\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/217 [00:00<00:10, 20.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      " Entering process \n",
      "193 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/217 [00:00<00:15, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "194Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 8/217 [00:00<00:24,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/217 [00:00<00:33,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 196Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/217 [00:01<00:31,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process 198\n",
      " \n",
      "199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-192:\n",
      "Process Process-191:\n",
      "Process Process-199:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (136506) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (136508) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (136504) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [01:37, 97.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-194:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (136587) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-200:\n",
      "Traceback (most recent call last):\n",
      "Process Process-197:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-195:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (137012) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (137016) - No such process\n",
      "\n",
      "        \n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (137048) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  197\n",
      "Exiting process Exiting process   192195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:07, 12.79s/it]\n",
      "  0%|          | 0/207 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 2 done\n",
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 3/207 [00:00<00:09, 22.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 200Entering process 201 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/207 [00:00<00:09, 20.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "202 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/207 [00:00<00:15, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/207 [00:00<00:21,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 204\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/207 [00:00<00:28,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/207 [00:01<00:35,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 9/207 [00:01<00:31,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "208Entering process \n",
      " 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-210:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bdace20>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=42129): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdace20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Process Process-209:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "Process Process-201:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "Traceback (most recent call last):\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "Process Process-202:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "Process Process-203:\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=42129): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdace20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bc94a90>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Process Process-204:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bde7280>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bd5ce80>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "Traceback (most recent call last):\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 42129\n",
      "    pid: 138770\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '42129', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=40446): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bc94a90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=43878): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bde7280>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bdb7550>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=46467): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bd5ce80>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "Process Process-208:\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=43866): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdb7550>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bcd0ca0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=40446): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bc94a90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=33775): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bcd0ca0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=43878): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bde7280>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=46467): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bd5ce80>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 40446\n",
      "    pid: 139010\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '40446', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=43866): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdb7550>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bc94e20>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 43878\n",
      "    pid: 139075\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '43878', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 46467\n",
      "    pid: 139078\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '46467', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=33775): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bcd0ca0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=39498): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bc94e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 43866\n",
      "    pid: 139124\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '43866', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "Process Process-205:\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "1it [02:44, 164.73s/it]  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 33775\n",
      "    pid: 139201\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '33775', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=39498): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bc94e20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "3it [02:45, 115.38s/it]  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bdbc5b0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "Process Process-206:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "4it [02:45, 80.88s/it]   File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 39498\n",
      "    pid: 139273\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '39498', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=38565): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdbc5b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "Process Process-207:\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bd85a60>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 156, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=38565): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdbc5b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "Traceback (most recent call last):\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=36301): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bd85a60>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 38565\n",
      "    pid: 139352\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '38565', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/http/client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 184, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x2ad35bdb8160>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=36301): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bd85a60>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=35212): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdb8160>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1561, in to_image\n",
      "    response = request_image_with_retrying(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "5it [02:47, 57.22s/it]  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 36301\n",
      "    pid: 139394\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '36301', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1471, in request_image_with_retrying\n",
      "    response = post(server_url + \"/\", data=json_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=35212): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x2ad35bdb8160>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "6it [02:48, 40.24s/it]  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1585, in to_image\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "For some reason plotly.py was unable to communicate with the\n",
      "local orca server process, even though the server process seems to be running.\n",
      "\n",
      "Please review the process and connection information below:\n",
      "\n",
      "orca status\n",
      "-----------\n",
      "    state: running\n",
      "    executable: /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca\n",
      "    version: 1.2.1\n",
      "    port: 35212\n",
      "    pid: 139448\n",
      "    command: ['/usr/bin/xvfb-run', '--auto-servernum', '--server-args', '-screen 0 640x480x24 +extension RANDR +extension GLX', '/ext3/miniconda3/bin/orca', 'serve', '-p', '35212', '--plotly', '/ext3/miniconda3/lib/python3.8/site-packages/plotly/package_data/plotly.min.js', '--graph-only', '--mathjax', 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:48, 16.87s/it]\n",
      "  0%|          | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/197 [00:00<00:30,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/197 [00:00<00:39,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/197 [00:00<00:37,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 4/197 [00:00<00:34,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 211Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/197 [00:00<00:32,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "212 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/197 [00:01<00:31,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 7/197 [00:01<00:32,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "214 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/197 [00:01<00:39,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 215\n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 9/197 [00:01<00:40,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 9/197 [00:02<00:44,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "218 \n",
      "219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-219:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-215:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (142697) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (142701) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [02:42, 162.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "Exiting process  211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:46, 114.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "Exiting process  212\n",
      "Exiting process  219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:48, 80.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 2 done\n",
      "Exiting process  213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:49, 56.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 3 done\n",
      "thread 4 done\n",
      "Exiting process  215\n",
      "Exiting process  217\n",
      "Exiting process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:50, 39.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:50, 17.02s/it]\n",
      "  0%|          | 0/187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/187 [00:00<00:08, 22.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 220Entering process \n",
      "221 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/187 [00:00<00:08, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "222 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/187 [00:00<00:12, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "223 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 7/187 [00:00<00:16, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 224Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 8/187 [00:00<00:23,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "225 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 9/187 [00:00<00:28,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 226Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 9/187 [00:01<00:25,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "228 \n",
      "229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-225:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (145082) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-221:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (145148) - No such process\n",
      "\n",
      "        \n",
      "1it [01:39, 99.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-227:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (145223) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-228:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (145263) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-229:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (145701) - No such process\n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  Exiting process 222 \n",
      "221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [02:24, 83.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 1 done\n",
      "thread 2 done\n",
      "Exiting process  223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:25, 58.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:25, 40.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 3 done\n",
      "thread 4 done\n",
      "thread 5 done\n",
      "thread 6 done\n",
      "thread 7 done\n",
      "thread 8 done\n",
      "Exiting process  229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:26, 14.61s/it]\n",
      "  0%|          | 0/177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 9 done\n",
      "Entering process  Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/177 [00:00<00:08, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 230Entering process 231\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/177 [00:00<00:08, 19.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/177 [00:00<00:11, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      " Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 7/177 [00:00<00:15, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 234Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 8/177 [00:00<00:20,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 \n",
      "Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 9/177 [00:00<00:24,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "236 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 9/177 [00:01<00:22,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "238 \n",
      "239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-233:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (146719) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "Process Process-232:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (147026) - No such process\n",
      "\n",
      "        \n",
      "Process Process-240:\n",
      "Traceback (most recent call last):\n",
      "Process Process-231:\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (147185) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1223, in validate_executable\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "An error occurred while trying to get the version of the orca executable.\n",
      "Here is the command that plotly.py ran to request the version\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --version\n",
      "\n",
      "This command returned the following error:\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (147208) - No such process\n",
      "\n",
      "        \n",
      "1it [01:40, 100.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 done\n",
      "thread 1 done\n",
      "thread 2 done\n",
      "Exiting process  233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [02:30, 75.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 3 done\n",
      "Exiting process  234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:34, 53.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  235thread 4 done\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:34, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 5 done\n",
      "Exiting process  236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:35, 26.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  thread 6 done\n",
      "237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:35, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process thread 7 done\n",
      " 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:36, 15.62s/it]\n",
      "  0%|          | 0/167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 8 done\n",
      "thread 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/167 [00:00<00:06, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process Entering process Entering process Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/167 [00:00<00:07, 22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Entering process 243242240 241Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 7/167 [00:00<00:07, 21.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "244\n",
      "\n",
      " Entering process \n",
      "245 Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 9/167 [00:00<00:07, 20.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "246Entering process "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 9/167 [00:00<00:14, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering process \n",
      "248\n",
      " 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-250:\n",
      "Process Process-247:\n",
      "Process Process-249:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"<ipython-input-15-77f889aec6ea>\", line 20, in process_function\n",
      "    fig.write_image(f'/scratch/prs392/capstone/original_simulation_2d/network_nikhil_num5_output/{index}.png', width=800, height=800)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/basedatatypes.py\", line 3280, in write_image\n",
      "    return pio.write_image(self, *args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 245, in write_image\n",
      "    img_data = to_image(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_kaleido.py\", line 103, in to_image\n",
      "    return to_image_orca(\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1535, in to_image\n",
      "    ensure_server()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1390, in ensure_server\n",
      "    validate_executable()\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "  File \"/ext3/miniconda3/lib/python3.8/site-packages/plotly/io/_orca.py\", line 1184, in validate_executable\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (148954) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (148952) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n",
      "ValueError: \n",
      "The orca executable is required in order to export figures as static images,\n",
      "but the executable that was found at '/ext3/miniconda3/bin/orca'\n",
      "does not seem to be a valid plotly orca executable. Please refer to the end of\n",
      "this message for details on what went wrong.\n",
      "\n",
      "If you haven't installed orca yet, you can do so using conda as follows:\n",
      "\n",
      "    $ conda install -c plotly plotly-orca\n",
      "\n",
      "Alternatively, see other installation methods in the orca project README at\n",
      "https://github.com/plotly/orca\n",
      "\n",
      "After installation is complete, no further configuration should be needed.\n",
      "\n",
      "If you have installed orca, then for some reason plotly.py was unable to\n",
      "locate it. In this case, set the `plotly.io.orca.config.executable`\n",
      "property to the full path of your orca executable. For example:\n",
      "\n",
      "    >>> plotly.io.orca.config.executable = '/path/to/orca'\n",
      "\n",
      "After updating this executable property, try the export operation again.\n",
      "If it is successful then you may want to save this configuration so that it\n",
      "will be applied automatically in future sessions. You can do this as follows:\n",
      "\n",
      "    >>> plotly.io.orca.config.save()\n",
      "\n",
      "If you're still having trouble, feel free to ask for help on the forums at\n",
      "https://community.plot.ly/c/api/python\n",
      "\n",
      "Here is the error that was returned by the command\n",
      "    $ /usr/bin/xvfb-run --auto-servernum --server-args -screen 0 640x480x24 +extension RANDR +extension GLX /ext3/miniconda3/bin/orca --help\n",
      "\n",
      "[Return code: 1]\n",
      "/usr/bin/xvfb-run: line 186: kill: (148958) - No such process\n",
      "\n",
      "Note: When used on Linux, orca requires an X11 display server, but none was\n",
      "detected. Please install Xvfb and configure plotly.py to run orca using Xvfb\n",
      "as follows:\n",
      "\n",
      "    >>> import plotly.io as pio\n",
      "    >>> pio.orca.config.use_xvfb = True\n",
      "    \n",
      "You can save this configuration for use in future sessions as follows:\n",
      "\n",
      "    >>> pio.orca.config.save() \n",
      "    \n",
      "See https://www.x.org/releases/X11R7.6/doc/man/man1/Xvfb.1.xhtml\n",
      "for more info on Xvfb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting process  247\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while True:\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    for index in tqdm.tqdm(range(i, new_output.shape[0])):\n",
    "        threads.append(Process(target=process_function, args=(index, )))\n",
    "        threads[-1].start()\n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            breakl\n",
    "\n",
    "    for index, thread in tqdm.tqdm(enumerate(threads)):\n",
    "        thread.join()\n",
    "        print(f'thread {index} done')\n",
    "        \n",
    "    if i > new_output.shape[0]:\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
